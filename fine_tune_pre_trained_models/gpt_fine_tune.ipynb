{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a12728-c596-4b24-884a-e8262cb354aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import OpenAIGPTTokenizer, OpenAIGPTLMHeadModel, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae9661-068a-4dae-8c8e-9147f3780648",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f9cf1-e418-4f1b-b589-0a2797c3d12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc285702-4a8b-4796-9165-d128447fbd25",
   "metadata": {},
   "source": [
    "# Dataset and Tokenizer Prep\n",
    "\n",
    "Loading the dataset, adding new tokens to the tokenizer's vocab, creating the Dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26c5899-de92-455c-91f9-9b19d4154e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_jsonl(filename : str) -> list:\n",
    "    \"\"\"\n",
    "    Reads .jsonl file\n",
    "    \"\"\"\n",
    "\n",
    "    with open (filename, 'r') as fp:\n",
    "        jsonl_data = [json.loads(x) for x in fp.readlines()]\n",
    "    \n",
    "    return jsonl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cd7ce-7ac2-4bc2-a9d4-6819f2be5ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load emotes file\n",
    "with open(\"../custom/emotes.txt\", 'r') as fp:\n",
    "    VALID_EMOTES = [x.strip() for x in fp.readlines()]\n",
    "\n",
    "IMG_TOKEN = \"[IMG]\"\n",
    "GIF_TOKEN = \"[GIF]\"\n",
    "LINK_TOKEN = \"[LINK]\"\n",
    "new_vocab = [IMG_TOKEN, GIF_TOKEN, LINK_TOKEN] + VALID_EMOTES\n",
    "\n",
    "SPECIAL_TOKENS = [\"[BOS]\", \"[SEP]\", \"[EOS]\", \"[PAD]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a3986-976a-4e49-8dc0-898665bd312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('openai-gpt')\n",
    "\n",
    "# https://stackoverflow.com/questions/76198051/how-to-add-new-tokens-to-an-existing-huggingface-tokenizer\n",
    "new_tokens = set(new_vocab) - set(tokenizer.vocab.keys())\n",
    "tokenizer.add_tokens(list(new_tokens))\n",
    "\n",
    "# We can add these special tokens to the vocabulary and the embeddings of the model:\n",
    "tokenizer.add_special_tokens({\n",
    "    'pad_token': '[PAD]', \n",
    "    'sep_token' : \"[SEP]\", \n",
    "    'bos_token' : \"[BOS]\",\n",
    "    'eos_token' : \"[EOS]\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646f312-3227-41a6-9f3a-bda3338d3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MimicDataset(Dataset):\n",
    "    def __init__(self, train_texts, tokenizer):\n",
    "        self.raw_strings = train_texts\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.raw_strings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        train_text = self.raw_strings[idx]\n",
    "        tokenized = self.tokenizer(train_text, return_tensors=\"pt\", padding='max_length', max_length=512, truncation=True)\n",
    "        input_ids = tokenized.input_ids.squeeze()\n",
    "        \n",
    "        labels = torch.full(input_ids.shape, self.tokenizer.pad_token_id)\n",
    "        labels[:-1] = input_ids[:-1]\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": input_ids,\n",
    "            \"labels\" : labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85703f1-5832-43d8-9362-a8c33608002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [x[\"train\"] for x in read_jsonl(f\"../messages/user_messages/{username}.jsonl\")]\n",
    "user_dataset = MimicDataset(train_data, tokenizer)\n",
    "data_loader = DataLoader(user_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185a342-4416-46bd-9b7d-b9cbfc6759e0",
   "metadata": {},
   "source": [
    "# Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6cf891-cba0-4ae0-bc85-15ea7daff3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAIGPTLMHeadModel.from_pretrained(\"openai-gpt\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3602bd5e-dd42-4d97-beeb-356f794dc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "num_epochs = 3\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in tqdm.tqdm(data_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        # labels = batch[\"labels\"].to(device)  # Shifted by one position\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass with custom masks\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        # outputs = model(input_ids, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_loss = total_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {average_loss}\")\n",
    "\n",
    "# Save the trained model if needed\n",
    "model.save_pretrained(f\"models/gpt/{username}/model\")\n",
    "tokenizer.save_pretrained(f\"models/gpt/{username}/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677ac88-ed77-43f9-9ded-4f3618cb068b",
   "metadata": {},
   "source": [
    "# Testing Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4ca6e4-6dd9-447b-979b-c9c919300331",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(f\"models/gpt/{username}/tokenizer\")\n",
    "model = AutoModelForCausalLM.from_pretrained(f\"models/gpt/{username}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5c494-e615-4511-b936-b1ee225fe7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"hello. how are you?\"\n",
    "inputs = tokenizer(f\"[BOS] {prompt} [SEP]\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(inputs, \n",
    "                         max_new_tokens=200, \n",
    "                         do_sample=True, \n",
    "                         top_p=0.97, \n",
    "                         temperature=1.0) # top_k=150,\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
